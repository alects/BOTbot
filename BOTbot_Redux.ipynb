{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "BOTbot Redux.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alects/BOTbot/blob/master/BOTbot_Redux.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTknlcUqs3Bq"
      },
      "source": [
        "# Leaf Classification CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwEmQ50Cs3Bs"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3kVqLHcs3Bt"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import sys, os, shutil, glob, random, csv, time\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfKscFbhs3Bt"
      },
      "source": [
        "## Data IO / Image Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTm5RZszs3Bu"
      },
      "source": [
        "#IO functions\n",
        "\n",
        "def load_image(file_path):\n",
        "    return cv2.imread(file_path)\n",
        "\n",
        "def create_directory(dirname):\n",
        "    try:\n",
        "        os.mkdir(dirname)\n",
        "    except FileExistsError:\n",
        "        pass\n",
        "\n",
        "def extract_names(label_file):\n",
        "    names = list()\n",
        "    with open('label_legend.csv', newline='') as f:\n",
        "        reader = csv.reader(f)\n",
        "        legend = dict(reader)\n",
        "    for img in label_file:\n",
        "        names.append(legend[str(img)])\n",
        "    return names\n",
        "\n",
        "def process_data(source_path, dest_path, desired_size, transform=False, edges=False):\n",
        "    create_directory(dest_path)\n",
        "    names = []\n",
        "    legend = dict()\n",
        "    j=0\n",
        "    species_folders = os.listdir(source_path)\n",
        "    for i, folder in enumerate(species_folders):\n",
        "        if folder[0] == '.':\n",
        "            continue\n",
        "        id = str(i).rjust(2, '0')\n",
        "        legend[folder] = id\n",
        "        folder_path = os.listdir(os.path.join(source_path, folder))\n",
        "        num_folders = len(folder_path)\n",
        "        clear_output(wait=True)\n",
        "        print(\"Folder:\", i, \"/100\", flush=True)\n",
        "        for jpgfile in folder_path:\n",
        "            #resize\n",
        "            img = load_image(os.path.join(source_path, folder, jpgfile))\n",
        "            old_size = img.shape[:2]\n",
        "            ratio = float(desired_size)/max(old_size)\n",
        "            new_size = tuple([int(x*ratio) for x in old_size])\n",
        "            img = cv2.resize(img, (new_size[1], new_size[0]))\n",
        "            delta_w = desired_size - new_size[1]\n",
        "            delta_h = desired_size - new_size[0]\n",
        "            top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "            left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "\n",
        "            color = [0, 0, 0]\n",
        "            new_im = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                value=color)\n",
        "    \n",
        "            #rename\n",
        "            new_name = id + str(j)\n",
        "            j += 1\n",
        "            fname = os.path.join(dest_path, new_name)\n",
        "            if edges:\n",
        "                new_im = cv2.Canny(new_im, 100, 200)\n",
        "            if transform:\n",
        "                # 2x mirror\n",
        "                img_flip_vert = np.flip(new_im, axis=0)\n",
        "                filename = os.path.join(fname + '_vert.jpg')\n",
        "                cv2.imwrite(filename, img_flip_vert)\n",
        "\n",
        "                img_flip_horiz = np.flip(new_im, axis=1)\n",
        "                filename = os.path.join(fname + '_horiz.jpg')\n",
        "                cv2.imwrite(filename, img_flip_horiz)\n",
        "\n",
        "                # rotate 3 times and save\n",
        "                for i in range(1, 4):\n",
        "                    img_flip_vert = cv2.rotate(img_flip_vert, cv2.ROTATE_90_CLOCKWISE)\n",
        "                    filename = os.path.join(fname + '_' + str(i*90) + '_vert.jpg')\n",
        "                    cv2.imwrite(filename, img_flip_vert)\n",
        "\n",
        "                    img_flip_horiz = cv2.rotate(img_flip_horiz, cv2.ROTATE_90_CLOCKWISE)\n",
        "                    filename = os.path.join(fname + '_' + str(i*90) + '_horiz.jpg')\n",
        "                    cv2.imwrite(filename, img_flip_horiz)\n",
        "            cv2.imwrite(os.path.join(fname+'.jpg'), new_im)\n",
        "    csv_name = 'label_legend.csv'\n",
        "    with open(csv_name, 'w') as csvfile:\n",
        "        for key in legend.keys():\n",
        "            csvfile.write(\"%d,%s\\n\"%(int(legend[key]), key))\n",
        "            \n",
        "def blackandwhite(img):\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    (thresh, img) = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
        "    return img / 255.0\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evFFSBFhs3Bv"
      },
      "source": [
        "#copy dataset into dest_name folder and create a 'label legend'\n",
        "\n",
        "def masterSet(dest_name='sixty-four', desired_size=64, trans=False, edge=False, test_perc=.2, seed=101):\n",
        "    #root_path = os.path.join(os.getcwd(), 'drive', 'My Drive', 'datasets')\n",
        "    root_path = os.path.join(os.getcwd(), 'datasets')\n",
        "    dest_path = os.path.join(root_path, dest_name)\n",
        "    process_data(os.path.join(root_path, '100 leaves plant species', 'data'), dest_path, desired_size, transform=trans, edges=edge)\n",
        "    data_path = dest_path\n",
        "    image_files = os.listdir(dest_path)\n",
        "    data = [load_image(os.path.join(data_path, file)) for file in image_files]\n",
        "    data = [blackandwhite(img) for img in data]\n",
        "    labels = [int(file[:2]) for file in image_files]\n",
        "    #Split processed dataset into training and validation\n",
        "    train_images, test_images, train_labels, test_labels = train_test_split(data, labels, test_size=test_perc, random_state=seed)\n",
        "    train_images = np.expand_dims(train_images, axis=-1)\n",
        "    train_labels = np.array(train_labels)\n",
        "    test_images = np.expand_dims(test_images, axis=-1)\n",
        "    test_labels = np.array(test_labels)\n",
        "    return train_images, test_images, train_labels, test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaO6-P8Xs3Bw",
        "outputId": "12a25d41-05c8-4d5a-cb01-aa66c4ad4f18"
      },
      "source": [
        "dest_name='sixty-four'\n",
        "desired_size=64\n",
        "trans=False \n",
        "edge=True\n",
        "test_perc=.2\n",
        "seed=101\n",
        "train_images, test_images, train_labels, test_labels = masterSet(dest_name, desired_size, trans, edge, test_perc, seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Folder: 99 /100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XJJoLRSs3Bx",
        "outputId": "621c8384-0023-4fbc-d6a5-5600cb00a411"
      },
      "source": [
        "print(type(train_images[0]), type(train_labels[0]))\n",
        "print(train_labels[:15])\n",
        "print(train_images.shape, train_labels.shape)\n",
        "print(train_images[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> <class 'numpy.int32'>\n",
            "[84 11 47 20 71 76 72 98 44 68 74  7  1 82 31]\n",
            "(1280, 64, 64, 1) (1280,)\n",
            "(64, 64, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TNngjXMs3Bx"
      },
      "source": [
        "## CONVOLUTIONAL NET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "F-gH-keFs3By"
      },
      "source": [
        "epoch = 13\n",
        "batch = 50\n",
        "\n",
        "def init_layers():\n",
        "    layers = [\n",
        "        tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(0.0001), input_shape=train_images.shape[1:]),\n",
        "        tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
        "        #tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=tf.nn.relu),\n",
        "        #tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        #tf.keras.layers.Dense(units=512, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(units=128, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(units=100, activation=tf.nn.softmax)\n",
        "    ]\n",
        "    return layers\n",
        "    \n",
        "layers = init_layers()\n",
        "    \n",
        "model = tf.keras.Sequential(layers)\n",
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss=tf.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
        "#history = model.fit(train_images, train_labels, epochs=epoch, validation_data=(test_images, test_labels), batch_size=batch)\n",
        "#print(history.history)\n",
        "model.save_weights(\"model.tf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEHRJa6Rs3By",
        "outputId": "d6a0f364-419d-45df-9418-80340658155c"
      },
      "source": [
        "'''hist_name = \"CNNhist_\" + str(desired_size) + ('_trans_' if trans == True else '_') + ('edge_' if edge == True else '') + str(epoch) + '_' + str(batch)\n",
        "create_directory('hist_stats')\n",
        "csv_file = os.path.join('hist_stats', hist_name + '.csv')\n",
        "hist = history.history\n",
        "try:\n",
        "    with open(csv_file, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(hist.keys())\n",
        "        writer.writerows(zip(*hist.values()))       \n",
        "except IOError:\n",
        "    print(\"I/O error\")\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hist_name = \"CNNhist_\" + str(desired_size) + (\\'_trans_\\' if trans == True else \\'_\\') + (\\'edge_\\' if edge == True else \\'\\') + str(epoch) + \\'_\\' + str(batch)\\ncreate_directory(\\'hist_stats\\')\\ncsv_file = os.path.join(\\'hist_stats\\', hist_name + \\'.csv\\')\\nhist = history.history\\ntry:\\n    with open(csv_file, \\'w\\', newline=\\'\\') as csvfile:\\n        writer = csv.writer(csvfile)\\n        writer.writerow(hist.keys())\\n        writer.writerows(zip(*hist.values()))       \\nexcept IOError:\\n    print(\"I/O error\")\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "remj1wY0s3By",
        "outputId": "e627436a-c3e6-41d0-d453-d7124638a8cb"
      },
      "source": [
        "'''eval_model = tf.keras.Sequential(layers)\n",
        "eval_model.load_weights(\"model.tf\")\n",
        "eval_predictions = eval_model.predict(test_images)\n",
        "cols = 4\n",
        "rows = np.ceil(len(test_images)/cols)\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(cols * 4, rows * 4)\n",
        "predicted_labels = np.argmax(eval_predictions, axis=1)\n",
        "predicted_names = extract_names(predicted_labels)\n",
        "predicted_correct = [1 if predicted_labels[i] ==  test_labels[i] else 0 for i in range(len(test_labels))  ]\n",
        "accuracy = np.sum(predicted_correct) / len(test_labels)\n",
        "print(\"Test Accuracy = \", accuracy)\n",
        "test_label_name = extract_names(test_labels)\n",
        "for i in range(15):\n",
        "    plt.subplot(rows, cols, i+1)\n",
        "    plt.imshow(test_images[i], cmap=\"gray\")\n",
        "    title = predicted_names[i][10:] + \" / \" + test_label_name[i][10:]\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eval_model = tf.keras.Sequential(layers)\\neval_model.load_weights(\"model.tf\")\\neval_predictions = eval_model.predict(test_images)\\ncols = 4\\nrows = np.ceil(len(test_images)/cols)\\nfig = plt.gcf()\\nfig.set_size_inches(cols * 4, rows * 4)\\npredicted_labels = np.argmax(eval_predictions, axis=1)\\npredicted_names = extract_names(predicted_labels)\\npredicted_correct = [1 if predicted_labels[i] ==  test_labels[i] else 0 for i in range(len(test_labels))  ]\\naccuracy = np.sum(predicted_correct) / len(test_labels)\\nprint(\"Test Accuracy = \", accuracy)\\ntest_label_name = extract_names(test_labels)\\nfor i in range(15):\\n    plt.subplot(rows, cols, i+1)\\n    plt.imshow(test_images[i], cmap=\"gray\")\\n    title = predicted_names[i][10:] + \" / \" + test_label_name[i][10:]\\n    plt.title(title)\\n    plt.axis(\\'off\\')\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CAqPxcps3Bz",
        "outputId": "db52cd24-390e-40d8-851a-30eaebf88d75"
      },
      "source": [
        "sizes = [10, 16, 32, 64]\n",
        "epochs = [i for i in range(1, 21)]\n",
        "transformations = [True, False]\n",
        "edges = [True, False]\n",
        "params = []\n",
        "for s in sizes:\n",
        "    for ep in epochs:\n",
        "        for tr in transformations:\n",
        "            for ed in edges:\n",
        "                params.append((s, ep, tr, ed))\n",
        "iters = len(params)\n",
        "iters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "320"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeUfbv2rs3Bz",
        "outputId": "17331c17-720f-4c25-cd38-1df5f3a316de"
      },
      "source": [
        "results = []\n",
        "# loop through various settings and get results\n",
        "for i, parameters in enumerate(params):\n",
        "    s, ep, tr, ed = parameters\n",
        "    train_images, test_images, train_labels, test_labels = masterSet(str(i), s, tr, ed, test_perc, seed)\n",
        "    print('{}% complete'.format(100 * i/iters))\n",
        "    #train\n",
        "    layers = init_layers()\n",
        "    model = tf.keras.Sequential(layers)\n",
        "    model.compile(optimizer=tf.optimizers.Adam(), loss=tf.losses.SparseCategoricalCrossentropy(), metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
        "    history = model.fit(train_images, train_labels, epochs=ep,validation_data=(test_images, test_labels), batch_size=batch)\n",
        "    model.save_weights(\"model.tf\")\n",
        "    \n",
        "    '''# test\n",
        "    eval_model = tf.keras.Sequential(layers)\n",
        "    eval_model.load_weights(\"model.tf\")\n",
        "    eval_predictions = eval_model.predict(np.expand_dims(test_images, axis=-1))\n",
        "    predicted_labels = np.argmax(eval_predictions, axis=1)\n",
        "    predicted_correct = [1 if predicted_labels[i] ==  test_labels[i] else 0 for i in range(len(test_labels))  ]\n",
        "    accuracy = np.sum(predicted_correct) / len(test_labels)\n",
        "    print(accuracy)\n",
        "    '''\n",
        "    results.append((parameters, history.history))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Folder: 19 /100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-10-199b0542e28e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0med\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmasterSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0med\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_perc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}% complete'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0miters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-3-bdcff7e29d43>\u001b[0m in \u001b[0;36mmasterSet\u001b[1;34m(dest_name, desired_size, trans, edge, test_perc, seed)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mroot_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'datasets'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdest_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'100 leaves plant species'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesired_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medges\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0medge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mdata_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdest_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mimage_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-2-8b806241e15a>\u001b[0m in \u001b[0;36mprocess_data\u001b[1;34m(source_path, dest_path, desired_size, transform, edges)\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mimg_flip_horiz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_im\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_horiz.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_flip_horiz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[1;31m# rotate 3 times and save\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPCbiuygs3Bz",
        "outputId": "f8332a39-0a1f-4fa9-e14d-ddffa3f2a87f"
      },
      "source": [
        "print(results[0])\n",
        "print(results[0][0]) # parameters [0] = size, [1] = epochs, [2] = transformations, [3] = edge detection\n",
        "print(results[0][1]) # dictionary of loss and training accuracy. ['loss'], ['sparse_categorical_accuracy']\n",
        "print(results[0][2]) # testing accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((10, 1, True, True), {'loss': [4.4372044959002075], 'sparse_categorical_accuracy': [0.025520833], 'val_loss': [4.135685842898157], 'val_sparse_categorical_accuracy': [0.038194444]})\n",
            "(10, 1, True, True)\n",
            "{'loss': [4.4372044959002075], 'sparse_categorical_accuracy': [0.025520833], 'val_loss': [4.135685842898157], 'val_sparse_categorical_accuracy': [0.038194444]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "tuple index out of range",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-11-eba3921faa31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# parameters [0] = size, [1] = epochs, [2] = transformations, [3] = edge detection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# dictionary of loss and training accuracy. ['loss'], ['sparse_categorical_accuracy']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# testing accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxpNSsC7s3B0"
      },
      "source": [
        "result_path = os.path.join(os.getcwd(), 'cnn-results-regularizer.txt'\n",
        "with open(result_path, 'w') as f:\n",
        "  f.write(str(results))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAkpszFas3B0"
      },
      "source": [
        "s10_ep_trf_edf = []\n",
        "s10_ep_trf_edt = []\n",
        "s10_ep_trt_edf = []\n",
        "s10_ep_trt_edt = []\n",
        "s16_ep_trf_edf = []\n",
        "s16_ep_trf_edt = []\n",
        "s16_ep_trt_edf = []\n",
        "s16_ep_trt_edt = []\n",
        "s32_ep_trf_edf = []\n",
        "s32_ep_trf_edt = []\n",
        "s32_ep_trt_edf = []\n",
        "s32_ep_trt_edt = []\n",
        "s64_ep_trf_edf = []\n",
        "s64_ep_trf_edt = []\n",
        "s64_ep_trt_edf = []\n",
        "s64_ep_trt_edt = []\n",
        "for params, tr_acc, te_acc in results:\n",
        "    size, ep, t, e = params\n",
        "    if (size == 10):\n",
        "        if (t):\n",
        "            if (e):\n",
        "                s10_ep_trt_edt.append((params, tr_acc, te_acc))\n",
        "            else:\n",
        "                s10_ep_trt_edf.append((params, tr_acc, te_acc))\n",
        "        else:\n",
        "            if (e):\n",
        "                s10_ep_trf_edt.append((params, tr_acc, te_acc))\n",
        "            else:\n",
        "                s10_ep_trf_edf.append((params, tr_acc, te_acc))\n",
        "    if (size == 16):\n",
        "        if (t):\n",
        "            if (e):\n",
        "                s16_ep_trt_edt.append((params, tr_acc, te_acc))\n",
        "            else:\n",
        "                s16_ep_trt_edf.append((params, tr_acc, te_acc))\n",
        "        else:\n",
        "            if (e):\n",
        "                s16_ep_trf_edt.append((params, tr_acc, te_acc))\n",
        "            else:\n",
        "                s16_ep_trf_edf.append((params, tr_acc, te_acc))\n",
        "    if (size == 32):\n",
        "        if (t):\n",
        "            if (e):\n",
        "                s32_ep_trt_edt.append((params, tr_acc, te_acc))\n",
        "            else:\n",
        "                s32_ep_trt_edf.append((params, tr_acc, te_acc))\n",
        "        else:\n",
        "            if (e):\n",
        "                s32_ep_trf_edt.append((params, tr_acc, te_acc))\n",
        "            else:\n",
        "                s32_ep_trf_edf.append((params, tr_acc, te_acc))\n",
        "    if (size == 64):\n",
        "        if (t):\n",
        "            if (e):\n",
        "                s64_ep_trt_edt.append((params, tr_acc, te_acc))\n",
        "            else:\n",
        "                s64_ep_trt_edf.append((params, tr_acc, te_acc))\n",
        "        else:\n",
        "            if (e):\n",
        "                s64_ep_trf_edt.append((params, tr_acc, te_acc))\n",
        "            else:\n",
        "                s64_ep_trf_edf.append((params, tr_acc, te_acc))\n",
        "\n",
        "groups = [s10_ep_trf_edf, s10_ep_trf_edt, s10_ep_trt_edf, s10_ep_trt_edt, \\\n",
        "          s16_ep_trf_edf, s16_ep_trf_edt, s16_ep_trt_edf, s16_ep_trt_edt, \\\n",
        "          s32_ep_trf_edf, s32_ep_trf_edt, s32_ep_trt_edf, s32_ep_trt_edt, \\\n",
        "          s64_ep_trf_edf, s64_ep_trf_edt, s64_ep_trt_edf, s64_ep_trt_edt]                \n",
        "styles = ['rs--', 'rs-', 'ro--', 'ro-', \\\n",
        "          'ys--', 'ys-', 'yo--', 'yo-', \\\n",
        "          'gs--', 'gs-', 'go--', 'go-', \\\n",
        "          'bs--', 'bs-', 'bo--', 'bo-']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g_xMikps3B0"
      },
      "source": [
        "fig = plt.gcf() \n",
        "fig.set_size_inches(12,10)\n",
        "ax = plt.subplot(1, 1, 1)\n",
        "ax.axis([0.95, 20.05, 0, 1])\n",
        "plt.title('CNN Accuracy')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "p1, = ax.plot([None], 'r', label=\"10x10 pixels\")\n",
        "p1, = ax.plot([None], 'y', label=\"16x16 pixels\")\n",
        "p1, = ax.plot([None], 'g', label=\"32x32 pixels\")\n",
        "p1, = ax.plot([None], 'b', label=\"64x64 pixels\")\n",
        "p1, = ax.plot([None], 'ks', label=\"no transformations\")\n",
        "p1, = ax.plot([None], 'ko', label=\"transformations\")\n",
        "p1, = ax.plot([None], 'k--', label=\"no edge detection\")\n",
        "p1, = ax.plot([None], 'k-', label=\"edge detection\")\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "ax.legend(handles, labels)\n",
        "for l, s in zip(groups, styles):\n",
        "    xs = [i for i in range(1,21)]\n",
        "    tr_ys = [y[1]['sparse_categorical_accuracy'][-1] for y in l]\n",
        "    te_ys = [y[2] for y in l]\n",
        "    plt.plot(xs, te_ys, s)    \n",
        "    plt.plot(xs, tr_ys, s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyb2ZnZVs3B1"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7PoVZIjs3B1"
      },
      "source": [
        "# Distance between instances x1 and x2\n",
        "def dist(x1, x2):\n",
        "    distance = x1 - x2\n",
        "    return np.linalg.norm(distance)\n",
        "\n",
        "# Predict label for instance x, using k nearest neighbors in training data\n",
        "def classify_knn(train_x, train_y, k, x):\n",
        "    # keep a list of all the distances with the values\n",
        "    distances = []\n",
        "    for i, data in enumerate(train_x):\n",
        "        # caluclate distance between x and data\n",
        "        distance = dist(x, data)\n",
        "        # add distance and label to list\n",
        "        distances.append((distance, train_y[i]))\n",
        "\n",
        "    # sort list of distances\n",
        "    distances.sort()\n",
        "\n",
        "    # tally up the results of the first k items in the sorted list\n",
        "    results = {}\n",
        "    best = (None, 0)\n",
        "    for i in range(k):\n",
        "        distance, label = distances[i]\n",
        "        # increment label by 1 if the label exists, or set to 1 if it doesn't\n",
        "        results[label] = results.get(label, 0) + 1\n",
        "        # keep track of the label with the most \"votes\"\n",
        "        if (results[label] > best[1]):\n",
        "            best = (label, results[label])\n",
        "\n",
        "    return best[0]\n",
        "\n",
        "# Run classifier and compute accuracy\n",
        "def runTest(test_x, test_y, train_x, train_y, k):\n",
        "    num_iters = test_x.shape[0]\n",
        "    correct = 0\n",
        "    i = 1\n",
        "    for (x,y) in zip(test_x, test_y):\n",
        "        clear_output(wait=True)\n",
        "        print('progress: {:.2f}% complete'.format(100* i/num_iters))\n",
        "        i += 1\n",
        "        if classify_knn(train_x, train_y, k, x) == y:\n",
        "            correct += 1\n",
        "    acc = float(correct)/len(test_x)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "D5hoLTpUs3B1"
      },
      "source": [
        "results = [((10, 1, 'transformations', 'only edge'), 0.6738888888888889), \\\n",
        "           ((10, 1, 'transformations', 'whole image'), 0.6947222222222222), \\\n",
        "           ((10, 1, 'no transformations', 'only edge'), 0.3675), \\\n",
        "           ((10, 1, 'no transformations', 'whole image'), 0.4025), \\\n",
        "           ((10, 3, 'transformations', 'only edge'), 0.43833333333333335), \\\n",
        "           ((10, 3, 'transformations', 'whole image'), 0.4661111111111111), \\\n",
        "           ((10, 3, 'no transformations', 'only edge'), 0.39), \\\n",
        "           ((10, 3, 'no transformations', 'whole image'), 0.4075), \\\n",
        "           ((10, 5, 'transformations', 'only edge'), 0.37083333333333335), \\\n",
        "           ((10, 5, 'transformations', 'whole image'), 0.4022222222222222), \\\n",
        "           ((10, 5, 'no transformations', 'only edge'), 0.3775), \\\n",
        "           ((10, 5, 'no transformations', 'whole image'), 0.3925), \\\n",
        "           ((10, 10, 'transformations', 'only edge'), 0.36194444444444446), \\\n",
        "           ((10, 10, 'transformations', 'whole image'), 0.39861111111111114), \\\n",
        "           ((10, 10, 'no transformations', 'only edge'), 0.3375), \\\n",
        "           ((10, 10, 'no transformations', 'whole image'), 0.385), \\\n",
        "           ((16, 1, 'transformations', 'only edge'), 0.7794444444444445), \\\n",
        "           ((16, 1, 'transformations', 'whole image'), 0.7991666666666667), \\\n",
        "           ((16, 1, 'no transformations', 'only edge'), 0.3525), \\\n",
        "           ((16, 1, 'no transformations', 'whole image'), 0.4325), \\\n",
        "           ((16, 3, 'transformations', 'only edge'), 0.5027777777777778), \\\n",
        "           ((16, 3, 'transformations', 'whole image'), 0.5547222222222222), \\\n",
        "           ((16, 3, 'no transformations', 'only edge'), 0.3575), \\\n",
        "           ((16, 3, 'no transformations', 'whole image'), 0.455), \\\n",
        "           ((16, 5, 'transformations', 'only edge'), 0.41555555555555557), \\\n",
        "           ((16, 5, 'transformations', 'whole image'), 0.48083333333333333), \\\n",
        "           ((16, 5, 'no transformations', 'only edge'), 0.365), \\\n",
        "           ((16, 5, 'no transformations', 'whole image'), 0.425), \\\n",
        "           ((16, 10, 'transformations', 'only edge'), 0.41), \\\n",
        "           ((16, 10, 'transformations', 'whole image'), 0.45861111111111114), \\\n",
        "           ((16, 10, 'no transformations', 'only edge'), 0.335), \\\n",
        "           ((16, 10, 'no transformations', 'whole image'), 0.4125), \\\n",
        "           ((32, 1, 'transformations', 'only edge'), 0.7877777777777778), \\\n",
        "           ((32, 1, 'transformations', 'whole image'), 0.8155555555555556), \\\n",
        "           ((32, 1, 'no transformations', 'only edge'), 0.4375), \\\n",
        "           ((32, 1, 'no transformations', 'whole image'), 0.515), \\\n",
        "           ((32, 3, 'transformations', 'only edge'), 0.5336111111111111), \\\n",
        "           ((32, 3, 'transformations', 'whole image'), 0.6011111111111112), \\\n",
        "           ((32, 3, 'no transformations', 'only edge'), 0.4225), \\\n",
        "           ((32, 3, 'no transformations', 'whole image'), 0.5225), \\\n",
        "           ((32, 5, 'transformations', 'only edge'), 0.4375), \\\n",
        "           ((32, 5, 'transformations', 'whole image'), 0.5402777777777777), \\\n",
        "           ((32, 5, 'no transformations', 'only edge'), 0.44), \\\n",
        "           ((32, 5, 'no transformations', 'whole image'), 0.5275), \\\n",
        "           ((32, 10, 'transformations', 'only edge'), 0.42583333333333334), \\\n",
        "           ((32, 10, 'transformations', 'whole image'), 0.5222222222222223), \\\n",
        "           ((32, 10, 'no transformations', 'only edge'), 0.39), \\\n",
        "           ((32, 10, 'no transformations', 'whole image'), 0.485), \\\n",
        "           ((64, 1, 'transformations', 'only edge'), 0.7766666666666666), \\\n",
        "           ((64, 1, 'transformations', 'whole image'), 0.8177777777777778), \\\n",
        "           ((64, 1, 'no transformations', 'only edge'), 0.4075), \\\n",
        "           ((64, 1, 'no transformations', 'whole image'), 0.5375), \\\n",
        "           ((64, 3, 'transformations', 'only edge'), 0.5116666666666667), \\\n",
        "           ((64, 3, 'transformations', 'whole image'), 0.6180555555555556), \\\n",
        "           ((64, 3, 'no transformations', 'only edge'), 0.395), \\\n",
        "           ((64, 3, 'no transformations', 'whole image'), 0.53), \\\n",
        "           ((64, 5, 'transformations', 'only edge'), 0.3794444444444444), \\\n",
        "           ((64, 5, 'transformations', 'whole image'), 0.5413888888888889), \\\n",
        "           ((64, 5, 'no transformations', 'only edge'), 0.375), \\\n",
        "           ((64, 5, 'no transformations', 'whole image'), 0.5025), \\\n",
        "           ((64, 10, 'transformations', 'only edge'), 0.36972222222222223), \\\n",
        "           ((64, 10, 'transformations', 'whole image'), 0.5363888888888889), \\\n",
        "           ((64, 10, 'no transformations', 'only edge'), 0.3425), \\\n",
        "           ((64, 10, 'no transformations', 'whole image'), 0.51)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lght21xs3B2"
      },
      "source": [
        "trt = 'transformations'\n",
        "trf = 'no transformations'\n",
        "edt = 'only edge'\n",
        "edf = 'whole image'\n",
        "s10_k_tf_ef = []\n",
        "s10_k_tf_et = []\n",
        "s10_k_tt_ef = []\n",
        "s10_k_tt_et = []\n",
        "s16_k_tf_ef = []\n",
        "s16_k_tf_et = []\n",
        "s16_k_tt_ef = []\n",
        "s16_k_tt_et = []\n",
        "s32_k_tf_ef = []\n",
        "s32_k_tf_et = []\n",
        "s32_k_tt_ef = []\n",
        "s32_k_tt_et = []\n",
        "s64_k_tf_ef = []\n",
        "s64_k_tf_et = []\n",
        "s64_k_tt_ef = []\n",
        "s64_k_tt_et = []\n",
        "for params, acc in results:\n",
        "    size, k, t, e = params\n",
        "    if (size == 10):\n",
        "        if (t == trt):\n",
        "            if (e == edt):\n",
        "                s10_k_tt_et.append((params, acc))\n",
        "            else:\n",
        "                s10_k_tt_ef.append((params, acc))\n",
        "        else:\n",
        "            if (e == edt):\n",
        "                s10_k_tf_et.append((params, acc))\n",
        "            else:\n",
        "                s10_k_tf_ef.append((params, acc))\n",
        "    if (size == 16):\n",
        "        if (t == trt):\n",
        "            if (e == edt):\n",
        "                s16_k_tt_et.append((params, acc))\n",
        "            else:\n",
        "                s16_k_tt_ef.append((params, acc))\n",
        "        else:\n",
        "            if (e == edt):\n",
        "                s16_k_tf_et.append((params, acc))\n",
        "            else:\n",
        "                s16_k_tf_ef.append((params, acc))\n",
        "    if (size == 32):\n",
        "        if (t == trt):\n",
        "            if (e == edt):\n",
        "                s32_k_tt_et.append((params, acc))\n",
        "            else:\n",
        "                s32_k_tt_ef.append((params, acc))\n",
        "        else:\n",
        "            if (e == edt):\n",
        "                s32_k_tf_et.append((params, acc))\n",
        "            else:\n",
        "                s32_k_tf_ef.append((params, acc))\n",
        "    if (size == 64):\n",
        "        if (t == trt):\n",
        "            if (e == edt):\n",
        "                s64_k_tt_et.append((params, acc))\n",
        "            else:\n",
        "                s64_k_tt_ef.append((params, acc))\n",
        "        else:\n",
        "            if (e == edt):\n",
        "                s64_k_tf_et.append((params, acc))\n",
        "            else:\n",
        "                s64_k_tf_ef.append((params, acc))\n",
        "\n",
        "groups = [s10_k_tf_ef, s10_k_tf_et, s10_k_tt_ef, s10_k_tt_et, \\\n",
        "          s16_k_tf_ef, s16_k_tf_et, s16_k_tt_ef, s16_k_tt_et, \\\n",
        "          s32_k_tf_ef, s32_k_tf_et, s32_k_tt_ef, s32_k_tt_et, \\\n",
        "          s64_k_tf_ef, s64_k_tf_et, s64_k_tt_ef, s64_k_tt_et]                \n",
        "styles = ['rs--', 'rs-', 'ro--', 'ro-', \\\n",
        "          'ys--', 'ys-', 'yo--', 'yo-', \\\n",
        "          'gs--', 'gs-', 'go--', 'go-', \\\n",
        "          'bs--', 'bs-', 'bo--', 'bo-']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu-neKe6s3B2"
      },
      "source": [
        "### size = color\n",
        "10 = r  \n",
        "16 = y  \n",
        "32 = g  \n",
        "64 = b  \n",
        "\n",
        "### t = shape\n",
        "trf = s  \n",
        "trt = o\n",
        "\n",
        "### e = line\n",
        "eff = --  \n",
        "eft = -"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woALOjwZs3B2"
      },
      "source": [
        "fig = plt.gcf() \n",
        "fig.set_size_inches(12,10)\n",
        "ax = plt.subplot(1, 1, 1)\n",
        "ax.axis([.95, 10.05, 0.3, .85])\n",
        "plt.title('K-NN Accuracy')\n",
        "plt.xlabel(\"k\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "p1, = ax.plot([None], 'r', label=\"10x10 pixels\")\n",
        "p1, = ax.plot([None], 'y', label=\"16x16 pixels\")\n",
        "p1, = ax.plot([None], 'g', label=\"32x32 pixels\")\n",
        "p1, = ax.plot([None], 'b', label=\"64x64 pixels\")\n",
        "p1, = ax.plot([None], 'ks', label=\"no transformations\")\n",
        "p1, = ax.plot([None], 'ko', label=\"transformations\")\n",
        "p1, = ax.plot([None], 'k--', label=\"no edge detection\")\n",
        "p1, = ax.plot([None], 'k-', label=\"edge detection\")\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "ax.legend(handles, labels)\n",
        "for l, s in zip(groups, styles):\n",
        "    xs = [x[0][1] for x in l]\n",
        "    ys = [y[1] for y in l]\n",
        "    plt.plot(xs, ys, s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGZNEqIws3B2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLGVrLAZs3B3"
      },
      "source": [
        "tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH__7zkjs3B3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}